{
<<<<<<< HEAD
 "cells": [],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
=======
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessing = pd.read_csv('../datasets/Road Traffic Accidents/RTA Dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "part_of_day\n",
       "Sore     3979\n",
       "Malam    2832\n",
       "Pagi     2800\n",
       "Siang    2705\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessing['Time'].value_counts()\n",
    "\n",
    "def categorize_time(t):\n",
    "    if 4 <= t.hour < 11:\n",
    "        return 'Pagi'\n",
    "    elif 11 <= t.hour < 15:\n",
    "        return 'Siang'\n",
    "    elif 15 <= t.hour < 19:\n",
    "        return 'Sore'\n",
    "    else:\n",
    "        return 'Malam'\n",
    "    \n",
    "df_preprocessing['Time'] = pd.to_datetime(df_preprocessing['Time'], format='%H:%M:%S').dt.time\n",
    "\n",
    "df_preprocessing['part_of_day'] = df_preprocessing['Time'].apply(categorize_time)\n",
    "df_preprocessing['part_of_day'].value_counts()\n",
    "\n",
    "# Pagi (04:00 - 10:59)\n",
    "# Siang (11:00 - 14:59)\n",
    "# Sore (15:00 - 18:59)\n",
    "# Malam (19:00 - 03:59)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age band of driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age_band_of_driver\n",
       "18-30       47.247483\n",
       "31-50       33.184475\n",
       "Over 51     12.869438\n",
       "Under 18     6.698603\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessing['Age_band_of_driver'].replace(\"Unknown\", np.nan, inplace=True)\n",
    "df_preprocessing['Age_band_of_driver'].fillna(df_preprocessing['Age_band_of_driver'].mode()[0], inplace=True)\n",
    "df_preprocessing['Age_band_of_driver'].value_counts(normalize=True) * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sex driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex_of_driver\n",
       "Male      94.308217\n",
       "Female     5.691783\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessing['Sex_of_driver'].replace(\"Unknown\", np.nan, inplace=True)\n",
    "df_preprocessing['Sex_of_driver'].fillna(df_preprocessing['Sex_of_driver'].mode()[0], inplace=True)\n",
    "\n",
    "\n",
    "df_preprocessing['Sex_of_driver'].value_counts(normalize=True) * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alasan menagapa modus ya karena mayoritas laki\" dan kita bakal cari jurnal untuk mendukung ini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# educational driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Educational_level\n",
       "Secondary education    9570\n",
       "Primary education      2163\n",
       "Higher education        362\n",
       "Low education           221\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessing['Educational_level'].replace(\"Unknown\", np.nan, inplace=True)\n",
    "df_preprocessing['Educational_level'].fillna(df_preprocessing['Educational_level'].mode()[0], inplace=True)\n",
    "\n",
    "education_mapping = {\n",
    "    \"Illiterate\": \"Low education\",\n",
    "    \"Writing & reading\": \"Low education\",\n",
    "    \"Elementary school\": \"Primary education\",\n",
    "    \"Junior high school\": \"Secondary education\",\n",
    "    \"High school\": \"Secondary education\",\n",
    "    \"Above high school\": \"Higher education\"\n",
    "}\n",
    "\n",
    "df_preprocessing['Educational_level'] = df_preprocessing['Educational_level'].map(education_mapping)\n",
    "\n",
    "df_preprocessing['Educational_level'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pake modus karne a yg unknown dikit dan biasanya kalo dikit ya pake modus, trs digolongin lagi supaya class nya gak terlalu banyak  dan pake prinsip UNESCO (2012) dalam International Standard Classification of Education (ISCED) menggunakan pengelompokan serupa untuk analisis pendidikan global."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vehicle driver relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessing['Vehicle_driver_relation'].replace(\"Unknown\", np.nan, inplace=True)\n",
    "df_preprocessing['Vehicle_driver_relation'].fillna(df_preprocessing['Vehicle_driver_relation'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "karnea presentasi nya dikit dan yap pake modus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# driving _exprerince"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessing['Driving_experience'].replace(\"unknown\", np.nan, inplace=True)\n",
    "df_preprocessing['Driving_experience'].fillna(df_preprocessing['Driving_experience'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cause of accident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cause_of_accident\n",
       "Human Error         10924\n",
       "External Factors      678\n",
       "Violation             367\n",
       "Vehicle Issues        286\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessing['Cause_of_accident'].replace(\"Unknown\", np.nan, inplace=True)\n",
    "df_preprocessing['Cause_of_accident'].fillna(df_preprocessing['Cause_of_accident'].mode()[0], inplace=True)\n",
    "\n",
    "cause_mapping = {\n",
    "    \"No distancing\": \"Human Error\",\n",
    "    \"Changing lane to the right\": \"Human Error\",\n",
    "    \"Changing lane to the left\": \"Human Error\",\n",
    "    \"Driving carelessly\": \"Human Error\",\n",
    "    \"No priority to vehicle\": \"Human Error\",\n",
    "    \"No priority to pedestrian\": \"Human Error\",\n",
    "    \"Driving at high speed\": \"Human Error\",\n",
    "    \"Overtaking\": \"Human Error\",\n",
    "    \"Driving to the left\": \"Human Error\",\n",
    "    \"Moving Backward\": \"Human Error\",\n",
    "    \n",
    "    \"Driving under the influence of drugs\": \"Violation\",\n",
    "    \"Drunk driving\": \"Violation\",\n",
    "    \n",
    "    \"Overloading\": \"Vehicle Issues\",\n",
    "    \"Overturning\": \"Vehicle Issues\",\n",
    "    \"Turnover\": \"Vehicle Issues\",\n",
    "    \n",
    "    \"Improper parking\": \"External Factors\",\n",
    "    \"Getting off the vehicle improperly\": \"External Factors\",\n",
    "    \"Other\": \"External Factors\",\n",
    "    \"Unknown\": \"External Factors\"\n",
    "}\n",
    "\n",
    "df_preprocessing['Cause_of_accident'] = df_preprocessing['Cause_of_accident'].map(cause_mapping)\n",
    "\n",
    "df_preprocessing['Cause_of_accident'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehcile driver relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessing['Vehicle_driver_relation'].replace(\"Unknown\", np.nan, inplace=True)\n",
    "df_preprocessing['Vehicle_driver_relation'].fillna(df_preprocessing['Vehicle_driver_relation'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# type of vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type_of_vehicle\n",
       "Car                6315\n",
       "Large Truck        2569\n",
       "Small Truck         811\n",
       "Small Bus           711\n",
       "Medium Truck        541\n",
       "Medium Bus          532\n",
       "Large Bus           404\n",
       "Two-Wheeler         198\n",
       "Special Vehicle     130\n",
       "Non-Motorized        76\n",
       "Three-Wheeler        29\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessing['Type_of_vehicle'].replace(\"Other\", np.nan, inplace=True)\n",
    "df_preprocessing['Type_of_vehicle'].fillna(df_preprocessing['Type_of_vehicle'].mode()[0], inplace=True)\n",
    "\n",
    "vehicle_mapping = {\n",
    "    \"Automobile\": \"Car\",\n",
    "    \"Stationwagen\": \"Car\",\n",
    "    \"Taxi\": \"Car\",\n",
    "    \n",
    "    \"Pick up upto 10Q\": \"Small Truck\",\n",
    "    \"Lorry (11?40Q)\": \"Medium Truck\",\n",
    "    \"Lorry (41?100Q)\": \"Large Truck\",\n",
    "    \"Long lorry\": \"Large Truck\",\n",
    "    \n",
    "    \"Public (12 seats)\": \"Small Bus\",\n",
    "    \"Public (13?45 seats)\": \"Medium Bus\",\n",
    "    \"Public (> 45 seats)\": \"Large Bus\",\n",
    "    \n",
    "    \"Motorcycle\": \"Two-Wheeler\",\n",
    "    \"Bajaj\": \"Three-Wheeler\",\n",
    "    \"Bicycle\": \"Two-Wheeler\",\n",
    "    \n",
    "    \"Special vehicle\": \"Special Vehicle\",\n",
    "    \"Ridden horse\": \"Non-Motorized\",\n",
    "    \"Turbo\": \"Special Vehicle\"\n",
    "}\n",
    "\n",
    "df_preprocessing['Type_of_vehicle'] = df_preprocessing['Type_of_vehicle'].map(vehicle_mapping)\n",
    "\n",
    "df_preprocessing['Type_of_vehicle'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lanes or medians "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessing['Lanes_or_Medians'].replace(\"Unknown\", np.nan, inplace=True)\n",
    "df_preprocessing['Lanes_or_Medians'].fillna(df_preprocessing['Lanes_or_Medians'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Road Allignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Road_allignment\n",
       "Flat Road      11102\n",
       "Steep Road       448\n",
       "Hilly Road       433\n",
       "Curved Road      220\n",
       "Other            113\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessing['Road_allignment'].replace(\"Unknown\", np.nan, inplace=True)\n",
    "df_preprocessing['Road_allignment'].fillna(df_preprocessing['Road_allignment'].mode()[0], inplace=True)\n",
    "\n",
    "road_alignment_grouped = {\n",
    "    \"Tangent road with flat terrain\": \"Flat Road\",\n",
    "    \"Tangent road with mild grade and flat terrain\": \"Flat Road\",\n",
    "    \"Tangent road with rolling terrain\": \"Hilly Road\",\n",
    "    \"Tangent road with mountainous terrain and\": \"Hilly Road\",\n",
    "    \"Steep grade downward with mountainous terrain\": \"Steep Road\",\n",
    "    \"Steep grade upward with mountainous terrain\": \"Steep Road\",\n",
    "    \"Gentle horizontal curve\": \"Curved Road\",\n",
    "    \"Sharp reverse curve\": \"Curved Road\",\n",
    "    \"Escarpments\": \"Other\"\n",
    "}\n",
    "\n",
    "df_preprocessing['Road_allignment'] = df_preprocessing['Road_allignment'].map(road_alignment_grouped)\n",
    "\n",
    "df_preprocessing['Road_allignment'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Hitung proporsi dari kategori yang diketahui\n",
    "# known_counts = df_preprocessing['Service_year_of_vehicle'].value_counts(normalize=True)\n",
    "# known_counts = known_counts.drop(\"Unknown\")  # Buang kategori \"Unknown\"\n",
    "\n",
    "# # Gantilah nilai \"Unknown\" secara acak sesuai proporsi\n",
    "# unknown_indices = df_preprocessing[df_preprocessing['Service_year_of_vehicle'] == \"Unknown\"].index\n",
    "# df_preprocessing.loc[unknown_indices, 'Service_year_of_vehicle'] = np.random.choice(\n",
    "#     known_counts.index, size=len(unknown_indices), p=known_counts.values\n",
    "# )\n",
    "\n",
    "# # Mapping kategori usia kendaraan\n",
    "# vehicle_age_mapping = {\n",
    "#     \"Below 1yr\": \"New Vehicle\",\n",
    "#     \"1-2yr\": \"New Vehicle\",\n",
    "#     \"2-5yrs\": \"Moderate Vehicle\",\n",
    "#     \"5-10yrs\": \"Moderate Vehicle\",\n",
    "#     \"Above 10yr\": \"Old Vehicle\"\n",
    "# }\n",
    "\n",
    "# df_preprocessing['Service_year_of_vehicle'] = df_preprocessing['Service_year_of_vehicle'].map(vehicle_age_mapping)\n",
    "\n",
    "# df_preprocessing['Service_year_of_vehicle'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# defect of vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessing.drop(columns=['Defect_of_vehicle'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time                              0\n",
       "Day_of_week                       0\n",
       "Age_band_of_driver                0\n",
       "Sex_of_driver                     0\n",
       "Educational_level                 0\n",
       "Vehicle_driver_relation           0\n",
       "Driving_experience                0\n",
       "Type_of_vehicle                   0\n",
       "Owner_of_vehicle                482\n",
       "Service_year_of_vehicle        3928\n",
       "Area_accident_occured           239\n",
       "Lanes_or_Medians                  0\n",
       "Road_allignment                   0\n",
       "Types_of_Junction               887\n",
       "Road_surface_type               172\n",
       "Road_surface_conditions           0\n",
       "Light_conditions                  0\n",
       "Weather_conditions                0\n",
       "Type_of_collision               155\n",
       "Number_of_vehicles_involved       0\n",
       "Number_of_casualties              0\n",
       "Vehicle_movement                308\n",
       "Casualty_class                    0\n",
       "Sex_of_casualty                   0\n",
       "Age_band_of_casualty              0\n",
       "Casualty_severity                 0\n",
       "Work_of_casuality              3198\n",
       "Fitness_of_casuality           2635\n",
       "Pedestrian_movement               0\n",
       "Cause_of_accident                61\n",
       "Accident_severity                 0\n",
       "part_of_day                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessing.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area accident occured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Area_accident_occured\n",
       "Commercial areas        4231\n",
       "Other                   3839\n",
       "Residential areas       2104\n",
       "Public service areas    1596\n",
       "Recreational areas       546\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessing['Area_accident_occured'] = df_preprocessing['Area_accident_occured'].str.strip()\n",
    "df_preprocessing['Area_accident_occured'].replace(\"Unknown\", np.nan, inplace=True)\n",
    "\n",
    "area_mapping = {\n",
    "    'Office areas': 'Commercial areas',\n",
    "    'Industrial areas': 'Commercial areas',\n",
    "    'Market areas': 'Commercial areas',\n",
    "    'Residential areas': 'Residential areas',\n",
    "    'Rural village areas': 'Residential areas',\n",
    "    'School areas': 'Public service areas',\n",
    "    'Hospital areas': 'Public service areas',\n",
    "    'Church areas': 'Public service areas',\n",
    "    'Recreational areas': 'Recreational areas',\n",
    "    'Outside rural areas': 'Recreational areas',\n",
    "    'Rural village areasOffice areas': 'Other'\n",
    "}\n",
    "\n",
    "df_preprocessing['Area_accident_occured'] = df_preprocessing['Area_accident_occured'].replace(area_mapping)\n",
    "df_preprocessing['Area_accident_occured'].isna().sum()\n",
    "\n",
    "df_preprocessing['Area_accident_occured'].fillna(df_preprocessing['Area_accident_occured'].mode()[0], inplace=True)\n",
    "df_preprocessing['Area_accident_occured'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# type of collision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessing['Type_of_collision'] = df_preprocessing['Type_of_collision'].str.strip()\n",
    "df_preprocessing['Type_of_collision'].replace(\"Unknown\", np.nan, inplace=True)\n",
    "\n",
    "df_preprocessing['Type_of_collision'].fillna(df_preprocessing['Type_of_collision'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# road surface type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Road_surface_type\n",
       "Asphalt         11549\n",
       "Earth roads       358\n",
       "Gravel roads      242\n",
       "Other             167\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "road_surface_mapping = {\n",
    "    \"Asphalt roads\": \"Asphalt\",\n",
    "    \"Asphalt roads with some distress\": \"Asphalt\"\n",
    "}\n",
    "df_preprocessing['Road_surface_type'] = df_preprocessing['Road_surface_type'].replace(road_surface_mapping)\n",
    "mode_road_surface = df_preprocessing['Road_surface_type'].mode()[0]\n",
    "df_preprocessing['Road_surface_type'].fillna(mode_road_surface, inplace=True)\n",
    "df_preprocessing['Road_surface_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light_conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Light_conditions\n",
       "Good lighting        8798\n",
       "Moderate lighting    3286\n",
       "Poor lighting         232\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_preprocessing['Light_conditions'] = df_preprocessing['Light_conditions'].str.strip()\n",
    "df_preprocessing['Light_conditions'].replace(\"Unknown\", np.nan, inplace=True)\n",
    "\n",
    "light_mapping = {\n",
    "    'Daylight': 'Good lighting',\n",
    "    'Darkness - lights lit': 'Moderate lighting',\n",
    "    'Darkness - no lighting': 'Poor lighting',\n",
    "    'Darkness - lights unlit': 'Poor lighting'\n",
    "}\n",
    "\n",
    "df_preprocessing['Light_conditions'] = df_preprocessing['Light_conditions'].replace(light_mapping)\n",
    "df_preprocessing['Light_conditions'].isna().sum()\n",
    "\n",
    "df_preprocessing['Light_conditions'].fillna(df_preprocessing['Light_conditions'].mode()[0], inplace=True)\n",
    "df_preprocessing['Light_conditions'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# weather conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Weather_conditions\n",
       "Clear    10480\n",
       "Rainy     1371\n",
       "Other      296\n",
       "Windy       98\n",
       "Snowy       61\n",
       "Foggy       10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessing['Weather_conditions'] = df_preprocessing['Weather_conditions'].str.strip()\n",
    "df_preprocessing['Weather_conditions'].replace(\"Unknown\", np.nan, inplace=True)\n",
    "\n",
    "weather_mapping = {\n",
    "    'Normal': 'Clear',\n",
    "    'Cloudy': 'Clear',\n",
    "    'Raining': 'Rainy',\n",
    "    'Raining and Windy': 'Rainy',\n",
    "    'Windy': 'Windy',\n",
    "    'Snow': 'Snowy',\n",
    "    'Fog or mist': 'Foggy',\n",
    "    'Other': 'Other'\n",
    "}\n",
    "\n",
    "df_preprocessing['Weather_conditions'] = df_preprocessing['Weather_conditions'].replace(weather_mapping)\n",
    "df_preprocessing['Weather_conditions'].isna().sum()\n",
    "\n",
    "df_preprocessing['Weather_conditions'].fillna(df_preprocessing['Weather_conditions'].mode()[0], inplace=True)\n",
    "df_preprocessing['Weather_conditions'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vehicle movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vehicle_movement\n",
       "Moving forward       8554\n",
       "Moving backward      1548\n",
       "Other                 937\n",
       "Turnover              489\n",
       "Stopping              449\n",
       "Junction movement     339\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessing['Vehicle_movement'] = df_preprocessing['Vehicle_movement'].str.strip()\n",
    "df_preprocessing['Vehicle_movement'].replace(\"Unknown\", np.nan, inplace=True)\n",
    "\n",
    "movement_mapping = {\n",
    "    'Going straight': 'Moving forward',\n",
    "    'Moving Backward': 'Moving backward',\n",
    "    'Reversing': 'Moving backward',\n",
    "    'Turnover': 'Turnover',\n",
    "    'Getting off': 'Stopping',\n",
    "    'Entering a junction': 'Junction movement',\n",
    "    'Overtaking': 'Junction movement',\n",
    "    'U-Turn': 'Junction movement',\n",
    "    'Waiting to go': 'Stopping',\n",
    "    'Stopping': 'Stopping',\n",
    "    'Parked': 'Stopping',\n",
    "    'Other': 'Other'\n",
    "}\n",
    "\n",
    "df_preprocessing['Vehicle_movement'] = df_preprocessing['Vehicle_movement'].replace(movement_mapping)\n",
    "df_preprocessing['Vehicle_movement'].fillna(df_preprocessing['Vehicle_movement'].mode()[0], inplace=True)\n",
    "df_preprocessing['Vehicle_movement'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# casuality class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessing['Casualty_class'].replace(\"na\", np.nan, inplace=True)\n",
    "df_preprocessing['Casualty_class'].fillna(df_preprocessing['Casualty_class'].mode()[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sex of casuaty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessing['Sex_of_casualty'].replace(\"na\", np.nan, inplace=True)\n",
    "df_preprocessing['Sex_of_casualty'].fillna(df_preprocessing['Sex_of_casualty'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age of band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessing['Age_band_of_casualty'].replace(\"na\", np.nan, inplace=True)\n",
    "df_preprocessing['Age_band_of_casualty'].fillna(df_preprocessing['Age_band_of_casualty'].mode()[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# casualty _serevity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " Casualty_severity\n",
       " 3     7076\n",
       " na    4443\n",
       " 2      771\n",
       " 1       26\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_preprocessing['Time'] = pd.to_datetime(df_preprocessing['Time'], format='%H:%M:%S', errors='coerce')\n",
    "grouped = df_preprocessing.groupby(['Time', 'Accident_severity'])['Casualty_severity'].apply(lambda x: x.mode()[0] if not x.isnull().all() else np.nan)\n",
    "\n",
    "df_preprocessing = df_preprocessing.merge(grouped.rename('Imputed_Casualty_severity'), on=['Time', 'Accident_severity'], how='left')\n",
    "df_preprocessing['Casualty_severity'].fillna(df_preprocessing['Imputed_Casualty_severity'], inplace=True)\n",
    "df_preprocessing.drop(columns=['Imputed_Casualty_severity'], inplace=True)\n",
    "df_preprocessing['Casualty_severity'].isnull().sum(), df_preprocessing['Casualty_severity'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work_of_casuality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Work_of_casuality\n",
       "Driver           7968\n",
       "Self-employed    2749\n",
       "Employee          756\n",
       "Other             645\n",
       "Student           134\n",
       "Unemployed         42\n",
       "Unknown            22\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_casualty_probs = df_preprocessing.groupby('Accident_severity')['Work_of_casuality'].value_counts(normalize=True).unstack()\n",
    "\n",
    "def impute_work_of_casualty(row):\n",
    "    if pd.isnull(row['Work_of_casuality']):\n",
    "        accident_severity = row['Accident_severity']\n",
    "        return np.random.choice(work_casualty_probs.columns, p=work_casualty_probs.loc[accident_severity].fillna(0).values)\n",
    "    return row['Work_of_casuality']\n",
    "\n",
    "df_preprocessing['Work_of_casuality'] = df_preprocessing.apply(impute_work_of_casualty, axis=1)\n",
    "df_preprocessing['Work_of_casuality'].isnull().sum()\n",
    "df_preprocessing['Work_of_casuality'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitness of casulity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fitness_of_casuality\n",
       "Normal    9627\n",
       "Deaf        18\n",
       "Other       18\n",
       "Blind       18\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessing['Fitness_of_casuality'] = df_preprocessing['Fitness_of_casuality'].replace('NormalNormal', 'Normal')\n",
    "\n",
    "df_preprocessing['Fitness_of_casuality'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessing['Fitness_of_casuality'].fillna('Normal', inplace=True)\n",
    "df_preprocessing['Fitness_of_casuality'].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pedestrian movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " array(['Not a Pedestrian', \"Crossing from driver's nearside\",\n",
       "        'Crossing from nearside - masked by parked or statioNot a Pedestrianry vehicle',\n",
       "        'Unknown or other',\n",
       "        'Crossing from offside - masked by  parked or statioNot a Pedestrianry vehicle',\n",
       "        'In carriageway, statioNot a Pedestrianry - not crossing  (standing or playing)',\n",
       "        'Walking along carriageway',\n",
       "        'In carriageway, statioNot a Pedestrianry - not crossing  (standing or playing) - masked by parked or statioNot a Pedestrianry vehicle'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "missing_pedestrian = df_preprocessing['Pedestrian_movement'].isnull().sum()\n",
    "\n",
    "predestrian_mapping = {\n",
    "    \"Crossing from nearside - masked by parked or stationary vehicle\": \"Crossing - masked by vehicle\",\n",
    "    \"Crossing from offside - masked by parked or stationary vehicle\": \"Crossing - masked by vehicle\",\n",
    "    \"Walking along in carriageway, facing traffic\": \"Walking along carriageway\",\n",
    "    \"Walking along in carriageway, back to traffic\": \"Walking along carriageway\",\n",
    "    \"In carriageway, stationary - not crossing (standing or playing)\": \"Stationary - not crossing\",\n",
    "    \"In carriageway, stationary - not crossing (standing or playing) - masked by parked or stationary vehicle\": \"Stationary - masked by vehicle\"\n",
    "}\n",
    "\n",
    "df_preprocessing['Pedestrian_movement'] = df_preprocessing['Pedestrian_movement'].replace(predestrian_mapping)\n",
    "unique_pedestrian_movement = df_preprocessing['Pedestrian_movement'].unique()\n",
    "\n",
    "missing_pedestrian, unique_pedestrian_movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cause of accident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cause_grouping = {\n",
    "    \"No distancing\": \"Distance & Priority Violation\",\n",
    "    \"No priority to vehicle\": \"Distance & Priority Violation\",\n",
    "    \"No priority to pedestrian\": \"Distance & Priority Violation\",\n",
    "    \"Changing lane to the right\": \"Unsafe Lane Change\",\n",
    "    \"Changing lane to the left\": \"Unsafe Lane Change\",\n",
    "    \"Driving to the left\": \"Unsafe Driving\",\n",
    "    \"Driving at high speed\": \"Speeding\",\n",
    "    \"Overspeed\": \"Speeding\",\n",
    "    \"Overloading\": \"Overloading & Overcapacity\",\n",
    "    \"Improper parking\": \"Improper Parking/Exit\",\n",
    "    \"Getting off the vehicle improperly\": \"Improper Parking/Exit\",\n",
    "    \"Driving carelessly\": \"Reckless Driving\",\n",
    "    \"Overtaking\": \"Reckless Driving\",\n",
    "    \"Overturning\": \"Reckless Driving\",\n",
    "    \"Turnover\": \"Reckless Driving\",\n",
    "    \"Driving under the influence of drugs\": \"DUI (Drugs/Alcohol)\",\n",
    "    \"Drunk driving\": \"DUI (Drugs/Alcohol)\",\n",
    "    \"Other\": \"Other/Unknown\",\n",
    "    \"Unknown\": \"Other/Unknown\"\n",
    "}\n",
    "\n",
    "df_preprocessing['Cause_of_accident'] = df_preprocessing['Cause_of_accident'].replace(cause_grouping)\n",
    "\n",
    "unique_cause_of_accident = df_preprocessing['Cause_of_accident'].unique()\n",
    "unique_cause_of_accident\n",
    "\n",
    "df_preprocessing['Cause_of_accident'].fillna(df_preprocessing['Cause_of_accident'].mode()[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time                              0\n",
       "Day_of_week                       0\n",
       "Age_band_of_driver                0\n",
       "Sex_of_driver                     0\n",
       "Educational_level                 0\n",
       "Vehicle_driver_relation           0\n",
       "Driving_experience                0\n",
       "Type_of_vehicle                   0\n",
       "Owner_of_vehicle                482\n",
       "Service_year_of_vehicle        3928\n",
       "Area_accident_occured             0\n",
       "Lanes_or_Medians                  0\n",
       "Road_allignment                   0\n",
       "Types_of_Junction               887\n",
       "Road_surface_type                 0\n",
       "Road_surface_conditions           0\n",
       "Light_conditions                  0\n",
       "Weather_conditions                0\n",
       "Type_of_collision                 0\n",
       "Number_of_vehicles_involved       0\n",
       "Number_of_casualties              0\n",
       "Vehicle_movement                  0\n",
       "Casualty_class                    0\n",
       "Sex_of_casualty                   0\n",
       "Age_band_of_casualty              0\n",
       "Casualty_severity                 0\n",
       "Work_of_casuality                 0\n",
       "Fitness_of_casuality              0\n",
       "Pedestrian_movement               0\n",
       "Cause_of_accident                 0\n",
       "Accident_severity                 0\n",
       "part_of_day                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessing.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# owner of vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_owner_vehicle = df_preprocessing['Owner_of_vehicle'].mode()[0]\n",
    "df_preprocessing['Owner_of_vehicle'].fillna(mode_owner_vehicle, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# type of junction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Types_of_Junction\n",
       "Y Shape        4543\n",
       "No junction    3837\n",
       "Crossing       2177\n",
       "Other           445\n",
       "Unknown         191\n",
       "O Shape         164\n",
       "T Shape          60\n",
       "X Shape          12\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessing['Types_of_Junction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Road_surface_type  Types_of_Junction\n",
       " Asphalt            Y Shape              0.398884\n",
       "                    No junction          0.335256\n",
       "                    Crossing             0.189953\n",
       "                    Other                0.039163\n",
       "                    Unknown              0.015907\n",
       "                    O Shape              0.014326\n",
       "                    T Shape              0.005488\n",
       "                    X Shape              0.001023\n",
       " Earth roads        No junction          0.354633\n",
       "                    Y Shape              0.325879\n",
       "                    Crossing             0.214058\n",
       "                    Unknown              0.047923\n",
       "                    Other                0.044728\n",
       "                    O Shape              0.006390\n",
       "                    T Shape              0.003195\n",
       "                    X Shape              0.003195\n",
       " Gravel roads       Y Shape              0.412844\n",
       "                    No junction          0.321101\n",
       "                    Crossing             0.206422\n",
       "                    Other                0.022936\n",
       "                    Unknown              0.022936\n",
       "                    O Shape              0.013761\n",
       " Other              Y Shape              0.425676\n",
       "                    No junction          0.351351\n",
       "                    Crossing             0.155405\n",
       "                    O Shape              0.033784\n",
       "                    Other                0.033784\n",
       " Name: proportion, dtype: float64,\n",
       " Cause_of_accident  Types_of_Junction\n",
       " External Factors   Y Shape              0.415094\n",
       "                    No junction          0.311321\n",
       "                    Crossing             0.212264\n",
       "                    Other                0.037736\n",
       "                    Unknown              0.011006\n",
       "                    O Shape              0.009434\n",
       "                    T Shape              0.003145\n",
       " Human Error        Y Shape              0.396115\n",
       "                    No junction          0.340200\n",
       "                    Crossing             0.187659\n",
       "                    Other                0.038160\n",
       "                    Unknown              0.016971\n",
       "                    O Shape              0.014420\n",
       "                    T Shape              0.005297\n",
       "                    X Shape              0.001177\n",
       " Vehicle Issues     Y Shape              0.400000\n",
       "                    No junction          0.286792\n",
       "                    Crossing             0.215094\n",
       "                    Other                0.052830\n",
       "                    Unknown              0.022642\n",
       "                    O Shape              0.015094\n",
       "                    T Shape              0.007547\n",
       " Violation          Y Shape              0.404192\n",
       "                    No junction          0.284431\n",
       "                    Crossing             0.215569\n",
       "                    Other                0.053892\n",
       "                    O Shape              0.020958\n",
       "                    Unknown              0.014970\n",
       "                    T Shape              0.005988\n",
       " Name: proportion, dtype: float64,\n",
       " Pedestrian_movement                                                                                                                    Types_of_Junction\n",
       " Crossing from driver's nearside                                                                                                        Y Shape              0.427481\n",
       "                                                                                                                                        No junction          0.297710\n",
       "                                                                                                                                        Crossing             0.206107\n",
       "                                                                                                                                        Other                0.030534\n",
       "                                                                                                                                        Unknown              0.022901\n",
       "                                                                                                                                        T Shape              0.007634\n",
       "                                                                                                                                        O Shape              0.007634\n",
       " Crossing from nearside - masked by parked or statioNot a Pedestrianry vehicle                                                          Y Shape              0.402556\n",
       "                                                                                                                                        No junction          0.319489\n",
       "                                                                                                                                        Crossing             0.172524\n",
       "                                                                                                                                        Other                0.044728\n",
       "                                                                                                                                        Unknown              0.031949\n",
       "                                                                                                                                        O Shape              0.019169\n",
       "                                                                                                                                        X Shape              0.006390\n",
       "                                                                                                                                        T Shape              0.003195\n",
       " Crossing from offside - masked by  parked or statioNot a Pedestrianry vehicle                                                          No junction          0.388060\n",
       "                                                                                                                                        Y Shape              0.373134\n",
       "                                                                                                                                        Crossing             0.179104\n",
       "                                                                                                                                        Unknown              0.029851\n",
       "                                                                                                                                        O Shape              0.014925\n",
       "                                                                                                                                        Other                0.014925\n",
       " In carriageway, statioNot a Pedestrianry - not crossing  (standing or playing)                                                         Y Shape              0.386364\n",
       "                                                                                                                                        No junction          0.295455\n",
       "                                                                                                                                        Crossing             0.227273\n",
       "                                                                                                                                        O Shape              0.068182\n",
       "                                                                                                                                        Other                0.022727\n",
       " In carriageway, statioNot a Pedestrianry - not crossing  (standing or playing) - masked by parked or statioNot a Pedestrianry vehicle  Y Shape              0.384615\n",
       "                                                                                                                                        No junction          0.384615\n",
       "                                                                                                                                        Crossing             0.153846\n",
       "                                                                                                                                        Unknown              0.076923\n",
       " Not a Pedestrian                                                                                                                       Y Shape              0.399072\n",
       "                                                                                                                                        No junction          0.335069\n",
       "                                                                                                                                        Crossing             0.190873\n",
       "                                                                                                                                        Other                0.038913\n",
       "                                                                                                                                        Unknown              0.015811\n",
       "                                                                                                                                        O Shape              0.014391\n",
       "                                                                                                                                        T Shape              0.005018\n",
       "                                                                                                                                        X Shape              0.000852\n",
       " Unknown or other                                                                                                                       No junction          0.384058\n",
       "                                                                                                                                        Y Shape              0.315217\n",
       "                                                                                                                                        Crossing             0.199275\n",
       "                                                                                                                                        Other                0.050725\n",
       "                                                                                                                                        Unknown              0.025362\n",
       "                                                                                                                                        T Shape              0.018116\n",
       "                                                                                                                                        O Shape              0.003623\n",
       "                                                                                                                                        X Shape              0.003623\n",
       " Walking along carriageway                                                                                                              Y Shape              0.521739\n",
       "                                                                                                                                        No junction          0.391304\n",
       "                                                                                                                                        Unknown              0.043478\n",
       "                                                                                                                                        Crossing             0.043478\n",
       " Name: proportion, dtype: float64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "junction_vs_road_surface = df_preprocessing.groupby(\"Road_surface_type\")[\"Types_of_Junction\"].value_counts(normalize=True)\n",
    "junction_vs_cause_accident = df_preprocessing.groupby(\"Cause_of_accident\")[\"Types_of_Junction\"].value_counts(normalize=True)\n",
    "junction_vs_pedestrian = df_preprocessing.groupby(\"Pedestrian_movement\")[\"Types_of_Junction\"].value_counts(normalize=True)\n",
    "\n",
    "junction_vs_road_surface, junction_vs_cause_accident, junction_vs_pedestrian\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_imputed = df_preprocessing.copy()\n",
    "\n",
    "# for col in [\"Road_surface_type\", \"Cause_of_accident\", \"Pedestrian_movement\"]:\n",
    "#     mode_per_category = df_imputed.groupby(col)[\"Types_of_Junction\"].agg(lambda x: x.mode()[0] if not x.mode().empty else \"No junction\")\n",
    "#     df_imputed.loc[df_imputed[\"Types_of_Junction\"].isna(), \"Types_of_Junction\"] = \\\n",
    "#         df_imputed.loc[df_imputed[\"Types_of_Junction\"].isna(), col].map(mode_per_category)\n",
    "\n",
    "# df_imputed[\"Types_of_Junction\"].fillna(\"No junction\", inplace=True)\n",
    "\n",
    "# # Cek hasil imputasi\n",
    "# df_imputed[\"Types_of_Junction\"].isnull().sum()\n",
    "\n",
    "mode_owner_vehicle = df_preprocessing['Types_of_Junction'].mode()[0]\n",
    "df_preprocessing['Types_of_Junction'].fillna(mode_owner_vehicle, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Service year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Service_year_of_vehicle\n",
       "Moderate Vehicle    9883\n",
       "Old Vehicle         1324\n",
       "New Vehicle         1109\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessing['Service_year_of_vehicle'].replace(\"Unknown\", np.nan, inplace=True)\n",
    "df_preprocessing['Service_year_of_vehicle'].fillna(df_preprocessing['Service_year_of_vehicle'].mode()[0], inplace=True)\n",
    "\n",
    "vehicle_age_mapping = {\n",
    "    \"Below 1yr\": \"New Vehicle\",\n",
    "    \"1-2yr\": \"New Vehicle\",\n",
    "    \"2-5yrs\": \"Moderate Vehicle\",\n",
    "    \"5-10yrs\": \"Moderate Vehicle\",\n",
    "    \"Above 10yr\": \"Old Vehicle\"\n",
    "}\n",
    "\n",
    "df_preprocessing['Service_year_of_vehicle'] = df_preprocessing['Service_year_of_vehicle'].map(vehicle_age_mapping)\n",
    "\n",
    "df_preprocessing['Service_year_of_vehicle'].value_counts()\n",
    "\n",
    "# df_preprocessing.drop[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Day_of_week</th>\n",
       "      <th>Age_band_of_driver</th>\n",
       "      <th>Sex_of_driver</th>\n",
       "      <th>Educational_level</th>\n",
       "      <th>Vehicle_driver_relation</th>\n",
       "      <th>Driving_experience</th>\n",
       "      <th>Type_of_vehicle</th>\n",
       "      <th>Owner_of_vehicle</th>\n",
       "      <th>Service_year_of_vehicle</th>\n",
       "      <th>...</th>\n",
       "      <th>Casualty_class</th>\n",
       "      <th>Sex_of_casualty</th>\n",
       "      <th>Age_band_of_casualty</th>\n",
       "      <th>Casualty_severity</th>\n",
       "      <th>Work_of_casuality</th>\n",
       "      <th>Fitness_of_casuality</th>\n",
       "      <th>Pedestrian_movement</th>\n",
       "      <th>Cause_of_accident</th>\n",
       "      <th>Accident_severity</th>\n",
       "      <th>part_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1900-01-01 17:02:00</td>\n",
       "      <td>Monday</td>\n",
       "      <td>18-30</td>\n",
       "      <td>Male</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Employee</td>\n",
       "      <td>1-2yr</td>\n",
       "      <td>Car</td>\n",
       "      <td>Owner</td>\n",
       "      <td>Old Vehicle</td>\n",
       "      <td>...</td>\n",
       "      <td>Driver or rider</td>\n",
       "      <td>Male</td>\n",
       "      <td>18-30</td>\n",
       "      <td>na</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Not a Pedestrian</td>\n",
       "      <td>Human Error</td>\n",
       "      <td>Slight Injury</td>\n",
       "      <td>Sore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1900-01-01 17:02:00</td>\n",
       "      <td>Monday</td>\n",
       "      <td>31-50</td>\n",
       "      <td>Male</td>\n",
       "      <td>Secondary education</td>\n",
       "      <td>Employee</td>\n",
       "      <td>Above 10yr</td>\n",
       "      <td>Large Bus</td>\n",
       "      <td>Owner</td>\n",
       "      <td>Moderate Vehicle</td>\n",
       "      <td>...</td>\n",
       "      <td>Driver or rider</td>\n",
       "      <td>Male</td>\n",
       "      <td>18-30</td>\n",
       "      <td>na</td>\n",
       "      <td>Driver</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Not a Pedestrian</td>\n",
       "      <td>Human Error</td>\n",
       "      <td>Slight Injury</td>\n",
       "      <td>Sore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1900-01-01 17:02:00</td>\n",
       "      <td>Monday</td>\n",
       "      <td>18-30</td>\n",
       "      <td>Male</td>\n",
       "      <td>Secondary education</td>\n",
       "      <td>Employee</td>\n",
       "      <td>1-2yr</td>\n",
       "      <td>Large Truck</td>\n",
       "      <td>Owner</td>\n",
       "      <td>Moderate Vehicle</td>\n",
       "      <td>...</td>\n",
       "      <td>Driver or rider</td>\n",
       "      <td>Male</td>\n",
       "      <td>31-50</td>\n",
       "      <td>3</td>\n",
       "      <td>Driver</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Not a Pedestrian</td>\n",
       "      <td>Human Error</td>\n",
       "      <td>Serious Injury</td>\n",
       "      <td>Sore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1900-01-01 01:06:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>18-30</td>\n",
       "      <td>Male</td>\n",
       "      <td>Secondary education</td>\n",
       "      <td>Employee</td>\n",
       "      <td>5-10yr</td>\n",
       "      <td>Large Bus</td>\n",
       "      <td>Governmental</td>\n",
       "      <td>Moderate Vehicle</td>\n",
       "      <td>...</td>\n",
       "      <td>Pedestrian</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-30</td>\n",
       "      <td>3</td>\n",
       "      <td>Driver</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Not a Pedestrian</td>\n",
       "      <td>Human Error</td>\n",
       "      <td>Slight Injury</td>\n",
       "      <td>Malam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1900-01-01 01:06:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>18-30</td>\n",
       "      <td>Male</td>\n",
       "      <td>Secondary education</td>\n",
       "      <td>Employee</td>\n",
       "      <td>2-5yr</td>\n",
       "      <td>Car</td>\n",
       "      <td>Owner</td>\n",
       "      <td>Moderate Vehicle</td>\n",
       "      <td>...</td>\n",
       "      <td>Driver or rider</td>\n",
       "      <td>Male</td>\n",
       "      <td>18-30</td>\n",
       "      <td>na</td>\n",
       "      <td>Driver</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Not a Pedestrian</td>\n",
       "      <td>Human Error</td>\n",
       "      <td>Slight Injury</td>\n",
       "      <td>Malam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Time Day_of_week Age_band_of_driver Sex_of_driver  \\\n",
       "0 1900-01-01 17:02:00      Monday              18-30          Male   \n",
       "1 1900-01-01 17:02:00      Monday              31-50          Male   \n",
       "2 1900-01-01 17:02:00      Monday              18-30          Male   \n",
       "3 1900-01-01 01:06:00      Sunday              18-30          Male   \n",
       "4 1900-01-01 01:06:00      Sunday              18-30          Male   \n",
       "\n",
       "     Educational_level Vehicle_driver_relation Driving_experience  \\\n",
       "0     Higher education                Employee              1-2yr   \n",
       "1  Secondary education                Employee         Above 10yr   \n",
       "2  Secondary education                Employee              1-2yr   \n",
       "3  Secondary education                Employee             5-10yr   \n",
       "4  Secondary education                Employee              2-5yr   \n",
       "\n",
       "  Type_of_vehicle Owner_of_vehicle Service_year_of_vehicle  ...  \\\n",
       "0             Car            Owner             Old Vehicle  ...   \n",
       "1       Large Bus            Owner        Moderate Vehicle  ...   \n",
       "2     Large Truck            Owner        Moderate Vehicle  ...   \n",
       "3       Large Bus     Governmental        Moderate Vehicle  ...   \n",
       "4             Car            Owner        Moderate Vehicle  ...   \n",
       "\n",
       "    Casualty_class Sex_of_casualty Age_band_of_casualty Casualty_severity  \\\n",
       "0  Driver or rider            Male                18-30                na   \n",
       "1  Driver or rider            Male                18-30                na   \n",
       "2  Driver or rider            Male                31-50                 3   \n",
       "3       Pedestrian          Female                18-30                 3   \n",
       "4  Driver or rider            Male                18-30                na   \n",
       "\n",
       "  Work_of_casuality Fitness_of_casuality Pedestrian_movement  \\\n",
       "0     Self-employed               Normal    Not a Pedestrian   \n",
       "1            Driver               Normal    Not a Pedestrian   \n",
       "2            Driver               Normal    Not a Pedestrian   \n",
       "3            Driver               Normal    Not a Pedestrian   \n",
       "4            Driver               Normal    Not a Pedestrian   \n",
       "\n",
       "  Cause_of_accident Accident_severity  part_of_day  \n",
       "0       Human Error     Slight Injury         Sore  \n",
       "1       Human Error     Slight Injury         Sore  \n",
       "2       Human Error    Serious Injury         Sore  \n",
       "3       Human Error     Slight Injury        Malam  \n",
       "4       Human Error     Slight Injury        Malam  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessing.to_csv('../datasets/clean.csv', index=False)\n",
    "\n",
    "df_preprocessing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_preprocessing.drop(columns=['Service_year_of_vehicle'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time                           0\n",
       "Day_of_week                    0\n",
       "Age_band_of_driver             0\n",
       "Sex_of_driver                  0\n",
       "Educational_level              0\n",
       "Vehicle_driver_relation        0\n",
       "Driving_experience             0\n",
       "Type_of_vehicle                0\n",
       "Owner_of_vehicle               0\n",
       "Service_year_of_vehicle        0\n",
       "Area_accident_occured          0\n",
       "Lanes_or_Medians               0\n",
       "Road_allignment                0\n",
       "Types_of_Junction              0\n",
       "Road_surface_type              0\n",
       "Road_surface_conditions        0\n",
       "Light_conditions               0\n",
       "Weather_conditions             0\n",
       "Type_of_collision              0\n",
       "Number_of_vehicles_involved    0\n",
       "Number_of_casualties           0\n",
       "Vehicle_movement               0\n",
       "Casualty_class                 0\n",
       "Sex_of_casualty                0\n",
       "Age_band_of_casualty           0\n",
       "Casualty_severity              0\n",
       "Work_of_casuality              0\n",
       "Fitness_of_casuality           0\n",
       "Pedestrian_movement            0\n",
       "Cause_of_accident              0\n",
       "Accident_severity              0\n",
       "part_of_day                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessing.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# import xgboost as xgb\n",
    "# import lightgbm as lgb\n",
    "# from catboost import CatBoostClassifier\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Load Dataset\n",
    "# df = df_preprocessing.copy()\n",
    "\n",
    "# # Handle Missing Values\n",
    "# df.replace(\"Unknown\", np.nan, inplace=True)\n",
    "# df.replace(\"na\", np.nan, inplace=True)\n",
    "\n",
    "# # Mengisi missing values dengan modus\n",
    "# for col in df.columns:\n",
    "#     df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "# # Pisahkan Fitur dan Target\n",
    "# X = df.drop(columns=['Accident_severity'])\n",
    "# y = df['Accident_severity']\n",
    "\n",
    "# # Identifikasi Kolom Kategorikal\n",
    "# cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# # Encoding untuk Model yang Membutuhkan\n",
    "# X_encoded = X.copy()\n",
    "# label_encoders = {}\n",
    "\n",
    "# for col in cat_cols:\n",
    "#     le = LabelEncoder()\n",
    "#     X_encoded[col] = le.fit_transform(X[col])\n",
    "#     label_encoders[col] = le\n",
    "\n",
    "# # Split Data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Model Training & Evaluation\n",
    "# models = {\n",
    "#     \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "#     \"XGBoost\": xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\"),\n",
    "#     \"LightGBM\": lgb.LGBMClassifier(),\n",
    "#     \"CatBoost\": CatBoostClassifier(silent=True)\n",
    "# }\n",
    "\n",
    "# for name, model in models.items():\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     acc = accuracy_score(y_test, y_pred)\n",
    "#     print(f\"{name} Accuracy: {acc:.4f}\")\n",
    "\n",
    "# # Feature Importance dengan Random Forest\n",
    "# rf_model = models[\"Random Forest\"]\n",
    "# feature_importances = rf_model.feature_importances_\n",
    "\n",
    "# # Visualisasi Feature Importance\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sorted_idx = np.argsort(feature_importances)[::-1]\n",
    "# plt.bar(range(len(feature_importances)), feature_importances[sorted_idx], align='center')\n",
    "# plt.xticks(range(len(feature_importances)), X_encoded.columns[sorted_idx], rotation=90)\n",
    "# plt.xlabel(\"Fitur\")\n",
    "# plt.ylabel(\"Pentingnya Fitur\")\n",
    "# plt.title(\"Feature Importance - Random Forest\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn import tree\n",
    "\n",
    "# # 1️⃣ **Load Dataset**\n",
    "# df = df_preprocessing.copy\n",
    "\n",
    "# # 2️⃣ **Handle Missing Values**\n",
    "# df.replace(\"Unknown\", np.nan, inplace=True)\n",
    "# df.replace(\"na\", np.nan, inplace=True)\n",
    "\n",
    "# # Mengisi missing values dengan modus\n",
    "# for col in df.columns:\n",
    "#     df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "# # 3️⃣ **Pisahkan Fitur dan Target**\n",
    "# X = df.drop(columns=['Accident_severity'])  # Fitur\n",
    "# y = df['Accident_severity']  # Target\n",
    "\n",
    "# # 4️⃣ **Identifikasi Kolom Kategorikal**\n",
    "# cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# # 5️⃣ **Encoding (Decision Tree butuh data numerik)**\n",
    "# X_encoded = X.copy()\n",
    "# label_encoders = {}\n",
    "\n",
    "# for col in cat_cols:\n",
    "#     le = LabelEncoder()\n",
    "#     X_encoded[col] = le.fit_transform(X[col])\n",
    "#     label_encoders[col] = le  # Simpan encoder untuk inference nanti\n",
    "\n",
    "# # 6️⃣ **Split Data**\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # 7️⃣ **Model Training (Decision Tree)**\n",
    "# dt_model = DecisionTreeClassifier(criterion=\"gini\", max_depth=5, random_state=42)\n",
    "# dt_model.fit(X_train, y_train)\n",
    "\n",
    "# # 8️⃣ **Evaluasi Model**\n",
    "# y_pred = dt_model.predict(X_test)\n",
    "# acc = accuracy_score(y_test, y_pred)\n",
    "# print(f\"Decision Tree Accuracy: {acc:.4f}\")\n",
    "# print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# # 9️⃣ **Visualisasi Decision Tree**\n",
    "# plt.figure(figsize=(20,10))\n",
    "# tree.plot_tree(dt_model, feature_names=X_encoded.columns, class_names=str(y.unique()), filled=True, fontsize=8)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time                           datetime64[ns]\n",
      "Day_of_week                             int64\n",
      "Age_band_of_driver                      int64\n",
      "Sex_of_driver                           int64\n",
      "Educational_level                       int64\n",
      "Vehicle_driver_relation                 int64\n",
      "Driving_experience                      int64\n",
      "Type_of_vehicle                         int64\n",
      "Owner_of_vehicle                        int64\n",
      "Service_year_of_vehicle                 int64\n",
      "Area_accident_occured                   int64\n",
      "Lanes_or_Medians                        int64\n",
      "Road_allignment                         int64\n",
      "Types_of_Junction                       int64\n",
      "Road_surface_type                       int64\n",
      "Road_surface_conditions                 int64\n",
      "Light_conditions                        int64\n",
      "Weather_conditions                      int64\n",
      "Type_of_collision                       int64\n",
      "Number_of_vehicles_involved             int64\n",
      "Number_of_casualties                    int64\n",
      "Vehicle_movement                        int64\n",
      "Casualty_class                          int64\n",
      "Sex_of_casualty                         int64\n",
      "Age_band_of_casualty                    int64\n",
      "Casualty_severity                       int64\n",
      "Work_of_casuality                       int64\n",
      "Fitness_of_casuality                    int64\n",
      "Pedestrian_movement                     int64\n",
      "Cause_of_accident                       int64\n",
      "Accident_severity                       int64\n",
      "part_of_day                             int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Loop semua kolom yang bertipe object (string/kategori)\n",
    "data = df_preprocessing.copy()\n",
    "\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "\n",
    "# Pastikan semua data sudah numerik\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('../datasets/clean.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy with Class Weights: 0.7382\n",
      "Classification Report for Decision Tree:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.03      0.03        37\n",
      "           1       0.13      0.11      0.12       363\n",
      "           2       0.83      0.86      0.85      2064\n",
      "\n",
      "    accuracy                           0.74      2464\n",
      "   macro avg       0.33      0.33      0.33      2464\n",
      "weighted avg       0.72      0.74      0.73      2464\n",
      "\n",
      "ROC AUC for Decision Tree: 0.49617601934937244\n",
      "Random Forest Accuracy with Class Weights: 0.8153\n",
      "Classification Report for Random Forest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        37\n",
      "           1       0.11      0.02      0.04       363\n",
      "           2       0.84      0.97      0.90      2064\n",
      "\n",
      "    accuracy                           0.82      2464\n",
      "   macro avg       0.32      0.33      0.31      2464\n",
      "weighted avg       0.72      0.82      0.76      2464\n",
      "\n",
      "ROC AUC for Random Forest: 0.5314798772172588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmadnafim/anaconda3/envs/bcc_intern/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [02:02:25] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy with Class Weights: 0.8304\n",
      "Classification Report for XGBoost:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        37\n",
      "           1       0.16      0.01      0.02       363\n",
      "           2       0.84      0.99      0.91      2064\n",
      "\n",
      "    accuracy                           0.83      2464\n",
      "   macro avg       0.33      0.33      0.31      2464\n",
      "weighted avg       0.73      0.83      0.76      2464\n",
      "\n",
      "ROC AUC for XGBoost: 0.5669672378583401\n",
      "\n",
      "Evaluasi dengan SMOTE Oversampling:\n",
      "Decision Tree Accuracy after SMOTE: 0.5499\n",
      "Classification Report for Decision Tree with SMOTE:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.16      0.03        37\n",
      "           1       0.14      0.25      0.18       363\n",
      "           2       0.84      0.61      0.71      2064\n",
      "\n",
      "    accuracy                           0.55      2464\n",
      "   macro avg       0.33      0.34      0.31      2464\n",
      "weighted avg       0.72      0.55      0.62      2464\n",
      "\n",
      "Random Forest Accuracy after SMOTE: 0.5572\n",
      "Classification Report for Random Forest with SMOTE:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.19      0.04        37\n",
      "           1       0.16      0.28      0.21       363\n",
      "           2       0.85      0.61      0.71      2064\n",
      "\n",
      "    accuracy                           0.56      2464\n",
      "   macro avg       0.34      0.36      0.32      2464\n",
      "weighted avg       0.73      0.56      0.63      2464\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmadnafim/anaconda3/envs/bcc_intern/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [02:02:50] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy after SMOTE: 0.5028\n",
      "Classification Report for XGBoost with SMOTE:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.35      0.05        37\n",
      "           1       0.16      0.31      0.21       363\n",
      "           2       0.85      0.54      0.66      2064\n",
      "\n",
      "    accuracy                           0.50      2464\n",
      "   macro avg       0.35      0.40      0.31      2464\n",
      "weighted avg       0.74      0.50      0.59      2464\n",
      "\n",
      "\n",
      "Evaluasi dengan Undersampling:\n",
      "Decision Tree Accuracy after Undersampling: 0.3600\n",
      "Classification Report for Decision Tree with Undersampling:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.49      0.04        37\n",
      "           1       0.16      0.36      0.22       363\n",
      "           2       0.86      0.36      0.51      2064\n",
      "\n",
      "    accuracy                           0.36      2464\n",
      "   macro avg       0.35      0.40      0.26      2464\n",
      "weighted avg       0.75      0.36      0.46      2464\n",
      "\n",
      "Random Forest Accuracy after Undersampling: 0.3742\n",
      "Classification Report for Random Forest with Undersampling:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.57      0.05        37\n",
      "           1       0.15      0.32      0.21       363\n",
      "           2       0.85      0.38      0.53      2064\n",
      "\n",
      "    accuracy                           0.37      2464\n",
      "   macro avg       0.34      0.42      0.26      2464\n",
      "weighted avg       0.74      0.37      0.47      2464\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmadnafim/anaconda3/envs/bcc_intern/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [02:03:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy after Undersampling: 0.3446\n",
      "Classification Report for XGBoost with Undersampling:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.41      0.04        37\n",
      "           1       0.15      0.33      0.20       363\n",
      "           2       0.85      0.35      0.49      2064\n",
      "\n",
      "    accuracy                           0.34      2464\n",
      "   macro avg       0.34      0.36      0.24      2464\n",
      "weighted avg       0.73      0.34      0.44      2464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Contoh: Menggunakan data frame 'data'\n",
    "# Pisahkan fitur dan target\n",
    "X = data.drop(columns=['Accident_severity', 'Time'])\n",
    "y = data['Accident_severity']\n",
    "\n",
    "# 🔹 **Label Encoding untuk target y**\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# 🔹 **Standarisasi data sebelum PCA**\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 🔹 **Reduksi Dimensi dengan PCA**\n",
    "pca = PCA(n_components=2)  # Misalnya kita hanya ambil 2 komponen utama\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# 🔹 **Split dataset untuk training & testing**\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# **SMOTE Oversampling**\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# **Undersampling dengan RandomUnderSampler**\n",
    "undersampler = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
    "X_train_undersample, y_train_undersample = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# **Decision Tree dengan Class Weights**\n",
    "dt_weighted = DecisionTreeClassifier(class_weight='balanced', random_state=42)\n",
    "dt_weighted.fit(X_train, y_train)\n",
    "y_pred_dt = dt_weighted.predict(X_test)\n",
    "acc_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(f\"Decision Tree Accuracy with Class Weights: {acc_dt:.4f}\")\n",
    "print(\"Classification Report for Decision Tree:\\n\", classification_report(y_test, y_pred_dt))\n",
    "print(\"ROC AUC for Decision Tree:\", roc_auc_score(y_test, dt_weighted.predict_proba(X_test), multi_class='ovr'))\n",
    "\n",
    "# **Random Forest dengan Class Weights**\n",
    "rf_weighted = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "rf_weighted.fit(X_train, y_train)\n",
    "y_pred_rf = rf_weighted.predict(X_test)\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Accuracy with Class Weights: {acc_rf:.4f}\")\n",
    "print(\"Classification Report for Random Forest:\\n\", classification_report(y_test, y_pred_rf))\n",
    "print(\"ROC AUC for Random Forest:\", roc_auc_score(y_test, rf_weighted.predict_proba(X_test), multi_class='ovr'))\n",
    "\n",
    "# **XGBoost dengan Class Weights**\n",
    "xgb_weighted = XGBClassifier(use_label_encoder=False, eval_metric='logloss', scale_pos_weight=1, random_state=42)\n",
    "xgb_weighted.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_weighted.predict(X_test)\n",
    "acc_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost Accuracy with Class Weights: {acc_xgb:.4f}\")\n",
    "print(\"Classification Report for XGBoost:\\n\", classification_report(y_test, y_pred_xgb))\n",
    "print(\"ROC AUC for XGBoost:\", roc_auc_score(y_test, xgb_weighted.predict_proba(X_test), multi_class='ovr'))\n",
    "\n",
    "# **SMOTE Oversampling Evaluasi**\n",
    "print(\"\\nEvaluasi dengan SMOTE Oversampling:\")\n",
    "dt_smote = DecisionTreeClassifier(random_state=42)\n",
    "dt_smote.fit(X_train_smote, y_train_smote)\n",
    "y_pred_dt_smote = dt_smote.predict(X_test)\n",
    "print(f\"Decision Tree Accuracy after SMOTE: {accuracy_score(y_test, y_pred_dt_smote):.4f}\")\n",
    "print(\"Classification Report for Decision Tree with SMOTE:\\n\", classification_report(y_test, y_pred_dt_smote))\n",
    "\n",
    "rf_smote = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_smote.fit(X_train_smote, y_train_smote)\n",
    "y_pred_rf_smote = rf_smote.predict(X_test)\n",
    "print(f\"Random Forest Accuracy after SMOTE: {accuracy_score(y_test, y_pred_rf_smote):.4f}\")\n",
    "print(\"Classification Report for Random Forest with SMOTE:\\n\", classification_report(y_test, y_pred_rf_smote))\n",
    "\n",
    "xgb_smote = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_smote.fit(X_train_smote, y_train_smote)\n",
    "y_pred_xgb_smote = xgb_smote.predict(X_test)\n",
    "print(f\"XGBoost Accuracy after SMOTE: {accuracy_score(y_test, y_pred_xgb_smote):.4f}\")\n",
    "print(\"Classification Report for XGBoost with SMOTE:\\n\", classification_report(y_test, y_pred_xgb_smote))\n",
    "\n",
    "# **Undersampling Evaluasi**\n",
    "print(\"\\nEvaluasi dengan Undersampling:\")\n",
    "dt_undersample = DecisionTreeClassifier(random_state=42)\n",
    "dt_undersample.fit(X_train_undersample, y_train_undersample)\n",
    "y_pred_dt_undersample = dt_undersample.predict(X_test)\n",
    "print(f\"Decision Tree Accuracy after Undersampling: {accuracy_score(y_test, y_pred_dt_undersample):.4f}\")\n",
    "print(\"Classification Report for Decision Tree with Undersampling:\\n\", classification_report(y_test, y_pred_dt_undersample))\n",
    "\n",
    "rf_undersample = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_undersample.fit(X_train_undersample, y_train_undersample)\n",
    "y_pred_rf_undersample = rf_undersample.predict(X_test)\n",
    "print(f\"Random Forest Accuracy after Undersampling: {accuracy_score(y_test, y_pred_rf_undersample):.4f}\")\n",
    "print(\"Classification Report for Random Forest with Undersampling:\\n\", classification_report(y_test, y_pred_rf_undersample))\n",
    "\n",
    "xgb_undersample = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_undersample.fit(X_train_undersample, y_train_undersample)\n",
    "y_pred_xgb_undersample = xgb_undersample.predict(X_test)\n",
    "print(f\"XGBoost Accuracy after Undersampling: {accuracy_score(y_test, y_pred_xgb_undersample):.4f}\")\n",
    "print(\"Classification Report for XGBoost with Undersampling:\\n\", classification_report(y_test, y_pred_xgb_undersample))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from dython.nominal import associations\n",
    "\n",
    "# # Baca dataset (gantilah dengan dataset yang sesuai)\n",
    "# # df = pd.read_csv('dataset.csv')  # Gantilah dengan path dataset Anda\n",
    "\n",
    "# # Hitung matriks korelasi\n",
    "# complete_correlation = associations(df_preprocessing, filename=None, figsize=(10,10))\n",
    "\n",
    "# # Ekstrak matriks korelasi\n",
    "# df_complete_corr = complete_correlation['corr']\n",
    "\n",
    "# # Filter hanya korelasi > 0.1 (abaikan diagonal 1.0)\n",
    "# filtered_corr = df_complete_corr[df_complete_corr.abs() > 0.1]\n",
    "\n",
    "# # Reset index agar lebih mudah dibaca\n",
    "# filtered_corr = filtered_corr.reset_index()\n",
    "\n",
    "# # Cetak hasil\n",
    "# print(filtered_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
>>>>>>> 2608b4ea38c1c6ed1010451126f454f22d0ffa8e
   "language": "python",
   "name": "python3"
  },
  "language_info": {
<<<<<<< HEAD
   "name": "python",
   "version": "3.12.7"
=======
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
>>>>>>> 2608b4ea38c1c6ed1010451126f454f22d0ffa8e
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
